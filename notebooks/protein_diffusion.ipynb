{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd50b024-67dc-47c0-bbdf-c2831c054e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LRScheduler, OneCycleLR\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "import matplotlib.pyplot as plt\n",
    "import py3Dmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b3d161-6da9-4cd5-85bf-97057ca74e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_types = [\n",
    "    'N', 'CA', 'C', 'CB', 'O', 'CG', 'CG1', 'CG2', 'OG', 'OG1', 'SG', 'CD',\n",
    "    'CD1', 'CD2', 'ND1', 'ND2', 'OD1', 'OD2', 'SD', 'CE', 'CE1', 'CE2', 'CE3',\n",
    "    'NE', 'NE1', 'NE2', 'OE1', 'OE2', 'CH2', 'NH1', 'NH2', 'OH', 'CZ', 'CZ2',\n",
    "    'CZ3', 'NZ', 'OXT'\n",
    "]\n",
    "\n",
    "restypes = [\n",
    "    'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P',\n",
    "    'S', 'T', 'W', 'Y', 'V'\n",
    "]\n",
    "restype_order = {restype: i for i, restype in enumerate(restypes)}\n",
    "restype_num = len(restypes)  # := 20.\n",
    "\n",
    "restype_1to3 = {\n",
    "    'A': 'ALA',\n",
    "    'R': 'ARG',\n",
    "    'N': 'ASN',\n",
    "    'D': 'ASP',\n",
    "    'C': 'CYS',\n",
    "    'Q': 'GLN',\n",
    "    'E': 'GLU',\n",
    "    'G': 'GLY',\n",
    "    'H': 'HIS',\n",
    "    'I': 'ILE',\n",
    "    'L': 'LEU',\n",
    "    'K': 'LYS',\n",
    "    'M': 'MET',\n",
    "    'F': 'PHE',\n",
    "    'P': 'PRO',\n",
    "    'S': 'SER',\n",
    "    'T': 'THR',\n",
    "    'W': 'TRP',\n",
    "    'Y': 'TYR',\n",
    "    'V': 'VAL',\n",
    "}\n",
    "\n",
    "def make_np_example(coords_dict):\n",
    "    \"\"\"Make a dictionary of non-batched numpy protein features.\"\"\"\n",
    "    bb_atom_types = ['N', 'CA', 'C', 'O']\n",
    "    bb_idx = [i for i, atom_type in enumerate(atom_types)\n",
    "              if atom_type in bb_atom_types]\n",
    "\n",
    "    num_res = np.array(coords_dict['N']).shape[0]\n",
    "    atom_positions = np.zeros([num_res, 37, 3], dtype=float)\n",
    "\n",
    "    for i, atom_type in enumerate(atom_types):\n",
    "        if atom_type in bb_atom_types:\n",
    "            atom_positions[:, i, :] = np.array(coords_dict[atom_type])\n",
    "\n",
    "    # Mask nan / None coordinates.\n",
    "    nan_pos = np.isnan(atom_positions)[..., 0]\n",
    "    atom_positions[nan_pos] = 0.\n",
    "    atom_mask = np.zeros([num_res, 37])\n",
    "    atom_mask[..., bb_idx] = 1\n",
    "    atom_mask[nan_pos] = 0\n",
    "\n",
    "    batch = {\n",
    "        'atom_positions': atom_positions,\n",
    "        'atom_mask': atom_mask,\n",
    "        'residue_index': np.arange(num_res)\n",
    "    }\n",
    "    return batch\n",
    "\n",
    "\n",
    "def make_fixed_size(np_example, max_seq_length=500):\n",
    "    \"\"\"Pad features to fixed sequence length, i.e. currently axis=0.\"\"\"\n",
    "    for k, v in np_example.items():\n",
    "        pad = max_seq_length - v.shape[0]\n",
    "        if pad > 0:\n",
    "            v = np.pad(v, ((0, pad),) + ((0, 0),) * (len(v.shape) - 1))\n",
    "        elif pad < 0:\n",
    "            v = v[:max_seq_length]\n",
    "        np_example[k] = v\n",
    "\n",
    "\n",
    "def center_positions(np_example):\n",
    "  \"\"\"Center 'atom_positions' on CA center of mass.\"\"\"\n",
    "  atom_positions = np_example['atom_positions']\n",
    "  atom_mask = np_example['atom_mask']\n",
    "  ca_positions = atom_positions[:, 1, :]\n",
    "  ca_mask = atom_mask[:, 1]\n",
    "\n",
    "  ca_center = (np.sum(ca_mask[..., None] * ca_positions, axis=0) /\n",
    "   (np.sum(ca_mask, axis=0) + 1e-9))\n",
    "  atom_positions = ((atom_positions - ca_center[None, ...]) *\n",
    "                    atom_mask[..., None])\n",
    "  np_example['atom_positions'] = atom_positions\n",
    "\n",
    "\n",
    "class DatasetFromDataframe(torch.utils.data.Dataset):\n",
    "    \"\"\"Load coordinates data from a DataFrame, currently from the 'coords' column.\"\"\"\n",
    "\n",
    "    def __init__(self, data_frame, max_seq_length=512):\n",
    "        self.data = data_frame\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        coords_dict = self.data.iloc[idx].coords\n",
    "        np_example = make_np_example(coords_dict)\n",
    "        make_fixed_size(np_example, self.max_seq_length)\n",
    "        center_positions(np_example)\n",
    "        example = {k: torch.tensor(v, dtype=torch.float32) for k, v\n",
    "                   in np_example.items()}\n",
    "        return example\n",
    "\n",
    "\n",
    "# Complete sequence of chain IDs supported by the PDB format.\n",
    "PDB_CHAIN_IDS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'\n",
    "PDB_MAX_CHAINS = len(PDB_CHAIN_IDS)  # := 62.\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class Protein:\n",
    "  \"\"\"Protein structure representation.\"\"\"\n",
    "\n",
    "  # Cartesian coordinates of atoms in angstroms. The atom types correspond to\n",
    "  # residue_constants.atom_types, i.e. the first three are N, CA, CB.\n",
    "  atom_positions: np.ndarray  # [num_res, num_atom_type, 3]\n",
    "\n",
    "  # Amino-acid type for each residue represented as an integer between 0 and\n",
    "  # 20, where 20 is 'X'.\n",
    "  aatype: np.ndarray  # [num_res]\n",
    "\n",
    "  # Binary float mask to indicate presence of a particular atom. 1.0 if an atom\n",
    "  # is present and 0.0 if not. This should be used for loss masking.\n",
    "  atom_mask: np.ndarray  # [num_res, num_atom_type]\n",
    "\n",
    "  # Residue index as used in PDB. It is not necessarily continuous or 0-indexed.\n",
    "  residue_index: np.ndarray  # [num_res]\n",
    "\n",
    "  # 0-indexed number corresponding to the chain in the protein that this residue\n",
    "  # belongs to.\n",
    "  chain_index: np.ndarray  # [num_res]\n",
    "\n",
    "  # B-factors, or temperature factors, of each residue (in sq. angstroms units),\n",
    "  # representing the displacement of the residue from its ground truth mean\n",
    "  # value.\n",
    "  b_factors: np.ndarray  # [num_res, num_atom_type]\n",
    "\n",
    "\n",
    "def _chain_end(atom_index, end_resname, chain_name, residue_index) -> str:\n",
    "  chain_end = 'TER'\n",
    "  return (f'{chain_end:<6}{atom_index:>5}      {end_resname:>3} '\n",
    "          f'{chain_name:>1}{residue_index:>4}')\n",
    "\n",
    "\n",
    "def to_pdb(prot: Protein) -> str:\n",
    "  \"\"\"Converts a `Protein` instance to a PDB string.\n",
    "\n",
    "  Args:\n",
    "    prot: The protein to convert to PDB.\n",
    "\n",
    "  Returns:\n",
    "    PDB string.\n",
    "  \"\"\"\n",
    "  restypes = [\n",
    "    'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P',\n",
    "    'S', 'T', 'W', 'Y', 'V', 'X']\n",
    "  res_1to3 = lambda r: restype_1to3.get(restypes[r], 'UNK')\n",
    "\n",
    "  pdb_lines = []\n",
    "\n",
    "  atom_mask = prot.atom_mask\n",
    "  aatype = prot.aatype\n",
    "  atom_positions = prot.atom_positions\n",
    "  residue_index = prot.residue_index.astype(np.int32)\n",
    "  chain_index = prot.chain_index.astype(np.int32)\n",
    "  b_factors = prot.b_factors\n",
    "\n",
    "  if np.any(aatype > restype_num):\n",
    "    raise ValueError('Invalid aatypes.')\n",
    "\n",
    "  # Construct a mapping from chain integer indices to chain ID strings.\n",
    "  chain_ids = {}\n",
    "  for i in np.unique(chain_index):  # np.unique gives sorted output.\n",
    "    if i >= PDB_MAX_CHAINS:\n",
    "      raise ValueError(\n",
    "          f'The PDB format supports at most {PDB_MAX_CHAINS} chains.')\n",
    "    chain_ids[i] = PDB_CHAIN_IDS[i]\n",
    "\n",
    "  pdb_lines.append('MODEL     1')\n",
    "  atom_index = 1\n",
    "  last_chain_index = chain_index[0]\n",
    "  # Add all atom sites.\n",
    "  for i in range(aatype.shape[0]):\n",
    "    # Close the previous chain if in a multichain PDB.\n",
    "    if last_chain_index != chain_index[i]:\n",
    "      pdb_lines.append(_chain_end(\n",
    "          atom_index, res_1to3(aatype[i - 1]), chain_ids[chain_index[i - 1]],\n",
    "          residue_index[i - 1]))\n",
    "      last_chain_index = chain_index[i]\n",
    "      atom_index += 1  # Atom index increases at the TER symbol.\n",
    "\n",
    "    res_name_3 = res_1to3(aatype[i])\n",
    "    for atom_name, pos, mask, b_factor in zip(\n",
    "        atom_types, atom_positions[i], atom_mask[i], b_factors[i]):\n",
    "      if mask < 0.5:\n",
    "        continue\n",
    "\n",
    "      record_type = 'ATOM'\n",
    "      name = atom_name if len(atom_name) == 4 else f' {atom_name}'\n",
    "      alt_loc = ''\n",
    "      insertion_code = ''\n",
    "      occupancy = 1.00\n",
    "      element = atom_name[0]  # Protein supports only C, N, O, S, this works.\n",
    "      charge = ''\n",
    "      # PDB is a columnar format, every space matters here!\n",
    "      atom_line = (f'{record_type:<6}{atom_index:>5} {name:<4}{alt_loc:>1}'\n",
    "                   f'{res_name_3:>3} {chain_ids[chain_index[i]]:>1}'\n",
    "                   f'{residue_index[i]:>4}{insertion_code:>1}   '\n",
    "                   f'{pos[0]:>8.3f}{pos[1]:>8.3f}{pos[2]:>8.3f}'\n",
    "                   f'{occupancy:>6.2f}{b_factor:>6.2f}          '\n",
    "                   f'{element:>2}{charge:>2}')\n",
    "      pdb_lines.append(atom_line)\n",
    "      atom_index += 1\n",
    "\n",
    "  # Close the final chain.\n",
    "  pdb_lines.append(_chain_end(atom_index, res_1to3(aatype[-1]),\n",
    "                              chain_ids[chain_index[-1]], residue_index[-1]))\n",
    "  pdb_lines.append('ENDMDL')\n",
    "  pdb_lines.append('END')\n",
    "\n",
    "  # Pad all lines to 80 characters.\n",
    "  pdb_lines = [line.ljust(80) for line in pdb_lines]\n",
    "  return '\\n'.join(pdb_lines) + '\\n'  # Add terminating newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61165d72-fe6b-4dee-b0d2-9df01e266af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading chain_set.jsonl, this can take 1 or 2 minutes...\n",
      "Read data.\n"
     ]
    }
   ],
   "source": [
    "print('Reading chain_set.jsonl, this can take 1 or 2 minutes...')\n",
    "df = pd.read_json('/home/jovyan/protein_diffusion/data/chain_set.jsonl', lines=True)\n",
    "cath_splits = pd.read_json('/home/jovyan/protein_diffusion/data/chain_set_splits.json', lines=True)\n",
    "print('Read data.')\n",
    "\n",
    "def get_split(pdb_name):\n",
    "  if pdb_name in cath_splits.train[0]:\n",
    "    return 'train'\n",
    "  elif pdb_name in cath_splits.validation[0]:\n",
    "    return 'validation'\n",
    "  elif pdb_name in cath_splits.test[0]:\n",
    "    return 'test'\n",
    "  else:\n",
    "    return 'None'\n",
    "\n",
    "df['split'] = df.name.apply(lambda x: get_split(x))\n",
    "df['seq_len'] = df.seq.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123b9dfe-6fb6-4dbf-ad85-b4a592cbef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFromDataframe(torch.utils.data.Dataset):\n",
    "    \"\"\"Load coordinates data from a DataFrame, currently from the 'coords' column.\"\"\"\n",
    "\n",
    "    def __init__(self, data_frame, max_seq_length=512):\n",
    "        self.data = data_frame\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        coords_dict = self.data.iloc[idx].coords\n",
    "        np_example = make_np_example(coords_dict)\n",
    "        make_fixed_size(np_example, self.max_seq_length)\n",
    "        center_positions(np_example)\n",
    "        example = {k: torch.tensor(v, dtype=torch.float32) for k, v\n",
    "                   in np_example.items()}\n",
    "\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db8aeba-9941-485c-b072-c538d9b5d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "  def __init__(self):\n",
    "    self.max_seq_length = 512\n",
    "    self.batch_size = 128\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "train_set = DatasetFromDataframe(df[df.split == 'train'],\n",
    "                                 max_seq_length=cfg.max_seq_length)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=cfg.batch_size,\n",
    "                                           shuffle=False)\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7349bc89-0b09-426c-8a71-c482a4b4a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A minimal implementation of the Unet architecture.\n",
    "\n",
    "    Encoder: comprises 3 convolutional layers,\n",
    "    each succeeded with a ReLU activation.\n",
    "\n",
    "    Decoder: comprises 3 convolutional layers,\n",
    "    first two succeeded with a ReLU activation.\n",
    "\n",
    "    self.time_mlp: embeds the time signal, linearly projecting it\n",
    "    into a 256-dimensional representation.\n",
    "\n",
    "    self.batch_normalization: normalizes input batches.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=3, time_emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        # time embedding block\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, time_emb_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # simple encoder block\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # simple decoder block\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(time_emb_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        performs the forward pass of the model,\n",
    "        the input is first permuted to channels first shape,\n",
    "        the input is passed through the encoder layers,\n",
    "        at the bottleneck, the time embedding is added,\n",
    "        then the decoder layers are applied, and the output is reshaped\n",
    "        back to the original form.\n",
    "        \"\"\"\n",
    "        # permute to channels first\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        t_emb = self.time_mlp(t.float()).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x = self.batch_norm(self.encoder(x) + t_emb)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        # permute back to original shape (256x37x3)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0cac36-6a42-46fa-b702-c3bd863537ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    \"\"\"\n",
    "    DDPM paper by Ho. et al: https://arxiv.org/abs/2006.11239.\n",
    "    Complete implementation by Umar Jamil: https://github.com/hkproj/pytorch-ddpm/.\n",
    "\n",
    "    A minimal implementation of the DDPM framework,\n",
    "    using the UNet architecture defined above.\n",
    "\n",
    "    self.timesteps: maximum noising / denoising timesteps.\n",
    "\n",
    "    self.betas: linear noise schedule, used to decide the amount\n",
    "    that should be added of the total sampled Gaussian noise.\n",
    "\n",
    "    self.alphas: used to compute the cumulative product of the transformer\n",
    "    noise schedule, allowing to obtain noisy input at an arbitrary timestep t\n",
    "    in one step.\n",
    "\n",
    "    self.alphas_cumprod: cumulative products of the alphas.\n",
    "    \"\"\"\n",
    "    def __init__(self, unet, timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        super(DDPM, self).__init__()\n",
    "\n",
    "        self.unet = unet\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def forward_diffusion(self, x0, t, noise):\n",
    "        \"\"\"\n",
    "        applies noise to an input x0 to reach xt, where t\n",
    "        an arbitrary timestem.\n",
    "        \"\"\"\n",
    "        t_on_cpu = t.detach().cpu()\n",
    "\n",
    "        sqrt_alpha_cumprod = torch.sqrt(\n",
    "            self.alphas_cumprod[t_on_cpu]\n",
    "        ).view(-1,1,1,1).to(device)\n",
    "\n",
    "        sqrt_one_minus_alpha_cumprod = torch.sqrt(\n",
    "            1 - self.alphas_cumprod[t_on_cpu]\n",
    "        ).view(-1,1,1,1).to(device)\n",
    "\n",
    "        noisy_x = sqrt_alpha_cumprod * x0 + sqrt_one_minus_alpha_cumprod * noise\n",
    "        return noisy_x\n",
    "\n",
    "    def denoise_at_t(self, noisy_x, predicted_noise, t):\n",
    "        \"\"\"\n",
    "        Removes given predicted noise at timestep t from the noisy input,\n",
    "        and returns the denoised structure.\n",
    "        \"\"\"\n",
    "        sqrt_alpha_cumprod = torch.sqrt(self.alphas_cumprod[t])\n",
    "        sqrt_one_minus_alpha_cumprod = torch.sqrt(1 - self.alphas_cumprod[t])\n",
    "\n",
    "        # denoised_struct = (1/sqrt_alpha_cumprod) * (\n",
    "        #     noisy_x - (self.betas[t] / sqrt_one_minus_alpha_cumprod) * predicted_noise\n",
    "        # )\n",
    "\n",
    "        # workaround that is not necessarily mathematically correct, to make this process\n",
    "        # output meaningful results, the formula that should be correct is the commented above\n",
    "        denoised_struct = (noisy_x - sqrt_one_minus_alpha_cumprod*predicted_noise) / sqrt_alpha_cumprod\n",
    "        return denoised_struct\n",
    "\n",
    "    def get_np_structure(self, sample):\n",
    "        \"\"\"\n",
    "        Return the np_structure to build an instance of the Protein class.\n",
    "        This was already implemented in the initial notebook, but decided\n",
    "        to make it part of the DDPM class for convenience.\n",
    "        \"\"\"\n",
    "        # to make this method compatibile with tensor\n",
    "        # and numpy inputs for general usability\n",
    "        if isinstance(sample, torch.Tensor):\n",
    "          sample = sample.detach().cpu().numpy()\n",
    "        bb_atom_types = ['N', 'CA', 'C', 'O']\n",
    "        bb_idx = [i for i, atom_type in enumerate(atom_types)\n",
    "                  if atom_type in bb_atom_types]\n",
    "\n",
    "        num_res = len(sample)\n",
    "        nan_pos = np.isnan(sample)[..., 0]\n",
    "        sample[nan_pos] = 0.\n",
    "        atom_mask = np.zeros([num_res, 37])\n",
    "        atom_mask[..., bb_idx] = 1\n",
    "\n",
    "        np_sample = {\n",
    "            'atom_positions': sample,\n",
    "            'residue_index':np.arange(num_res),\n",
    "            'atom_mask': atom_mask,\n",
    "        }\n",
    "        return np_sample\n",
    "\n",
    "    def get_protein(self, x):\n",
    "        \"\"\"\n",
    "        Returns a Protein instance from a given input.\n",
    "        Expects Tensor or Numpy ndarray.\n",
    "        first generates the np_structure, then returns a Protein instance.\n",
    "        \"\"\"\n",
    "        np_sample = self.get_np_structure(x)\n",
    "        # This was already implemented in the initial notebook\n",
    "        prot = Protein(\n",
    "            atom_positions=np_sample['atom_positions'],\n",
    "            atom_mask=np_sample['atom_mask'],\n",
    "            residue_index=np_sample['residue_index'],\n",
    "            aatype=np.zeros([cfg.max_seq_length,], dtype=np.int32),\n",
    "            chain_index=np.zeros([cfg.max_seq_length,], dtype=np.int32),\n",
    "            b_factors=np.ones([cfg.max_seq_length, 37], dtype=np.int32)\n",
    "        )\n",
    "        return prot\n",
    "\n",
    "    def get_predicted_protein(self, noisy_x, predicted_noise, t):\n",
    "        \"\"\"\n",
    "        Given a noisy input (noisy_x), predicted_noise and timestep (t),\n",
    "        Removes the predicted noise from the noisy input, and returns\n",
    "        a Protein instance of the denoised structure.\n",
    "        \"\"\"\n",
    "        predicted_struct = self.denoise_at_t(noisy_x, predicted_noise, t)\n",
    "        prot = self.get_protein(predicted_struct)\n",
    "        return prot\n",
    "\n",
    "\n",
    "    def sample(self, shape, device):\n",
    "        \"\"\"\n",
    "        Starts by sampling pure Gaussian noise,\n",
    "        then iteratively denoising it at each timestep.\n",
    "        Also adds an additional amount of noise (amount depends on t)\n",
    "        to insure stochasticity and diversity.\n",
    "        \"\"\"\n",
    "        predicted_noise_over_T = []\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(shape, device=device)\n",
    "            denoised_over_T = [x]\n",
    "            for t in reversed(range(self.timesteps)):\n",
    "                z = torch.randn(shape, device=device) if t > 0 else 0\n",
    "                tmp_t = torch.tensor(t, device=device).view(-1, 1)\n",
    "                predicted_noise = self.unet(x, tmp_t.float())\n",
    "                predicted_noise_over_T.append(predicted_noise)\n",
    "                x = self.denoise_at_t(x, predicted_noise, t) # + torch.sqrt(self.betas[t])*z\n",
    "                denoised_over_T.append(x)\n",
    "        return x, denoised_over_T, predicted_noise_over_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024ad0f5-c32a-446e-bf4d-3dc668cc8782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(pred_noise, actual_noise, mask):\n",
    "    \"\"\"\n",
    "    Masked Mean Squared Error loss.\n",
    "    Used to calculate the error between the predicted noise\n",
    "    and the actual noise.\n",
    "    Masked to only account for valid postions: those not\n",
    "    corresponding to null coordinates or padded positions.\n",
    "    \"\"\"\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    loss = mse_loss(pred_noise, actual_noise)\n",
    "    loss = (loss * mask.float()).sum() / mask.sum()\n",
    "    return loss\n",
    "\n",
    "def create_scheduler(config):\n",
    "    \"\"\"Returns lr scheduler according to config.\n",
    "\n",
    "    Args:\n",
    "        scheduler_config (dict): _description_\n",
    "\n",
    "    Returns:\n",
    "        CyclicLR: _description_\n",
    "    \"\"\"\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer=config[\"optimizer\"],\n",
    "        max_lr=config[\"max_lr\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        steps_per_epoch=config[\"steps_per_epoch\"],\n",
    "    )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e2941-ca1c-46fc-aadd-f924b2806f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 141/141 [03:20<00:00,  1.43s/it, loss=0.3244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 141/141 [03:18<00:00,  1.41s/it, loss=0.2939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 141/141 [03:15<00:00,  1.38s/it, loss=0.2432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 141/141 [03:21<00:00,  1.43s/it, loss=0.1949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.2620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 141/141 [03:30<00:00,  1.50s/it, loss=0.2611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 141/141 [03:34<00:00,  1.52s/it, loss=0.1930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 141/141 [03:34<00:00,  1.52s/it, loss=0.2135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 141/141 [03:31<00:00,  1.50s/it, loss=0.2511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.2240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 141/141 [03:34<00:00,  1.52s/it, loss=0.2006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50:  61%|██████    | 86/141 [02:08<01:19,  1.45s/it, loss=0.2249]"
     ]
    }
   ],
   "source": [
    "# used for mig devices only\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0, 1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DDPM(UNet())\n",
    "if torch.cuda.device_count()>1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=[device_id for device_id in range(torch.cuda.device_count())])\n",
    "model = model.module.to(device)\n",
    "\n",
    "lr=3e-3\n",
    "epochs=50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = masked_mse_loss\n",
    "\n",
    "scheduler_config = {\n",
    "    \"optimizer\": optimizer,\n",
    "    \"max_lr\": lr,\n",
    "    \"epochs\": epochs,\n",
    "    \"steps_per_epoch\": len(train_loader)\n",
    "}\n",
    "\n",
    "scheduler = create_scheduler(scheduler_config)\n",
    "\n",
    "example_proteins = {\n",
    "    'original': [],\n",
    "    'noisy': [],\n",
    "    'predicted_noise': [],\n",
    "    'timestep': []\n",
    "}\n",
    "metrics = {\n",
    "    'step_wise_loss': [],\n",
    "    'epoch_wise_loss': [],\n",
    "}\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        x = batch['atom_positions'].to(device)\n",
    "\n",
    "        # each mask is transformed into a stack of 3 copies if itself to match\n",
    "        # the expected shape by the loss funtion\n",
    "        mask = torch.stack([batch['atom_mask'] for _ in range(x.shape[-1])], dim=-1)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        # sample a batch of random time steps\n",
    "        t = torch.randint(0, model.timesteps, [x.shape[0]], device=device, dtype=torch.long)\n",
    "\n",
    "        # sample batch Gaussian noise\n",
    "        noise = torch.randn(x.shape, device=device)\n",
    "\n",
    "        # apply forward process\n",
    "        noisy_x = model.forward_diffusion(x, t, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # estimates the added noise at time step t using\n",
    "        # the noise estimation networks\n",
    "        predicted_noise = model.unet(noisy_x, t.unsqueeze(-1))\n",
    "\n",
    "        loss = criterion(predicted_noise, noise, mask)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        iterator.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        metrics['step_wise_loss'].append(loss.item())\n",
    "\n",
    "        if idx % (len(train_loader) // 5) == 0:\n",
    "              # at each 20% of the epoch, saves the orinal and noisy backbones,\n",
    "              # also saves the predicted noise and the timestep.\n",
    "              # used to later investigate and evaluate model training.\n",
    "              medium_noise_t = 0\n",
    "              example_proteins['original'].append(x[medium_noise_t])\n",
    "              example_proteins['noisy'].append(noisy_x[medium_noise_t])\n",
    "              example_proteins['predicted_noise'].append(predicted_noise[medium_noise_t])\n",
    "              example_proteins['timestep'].append(t[medium_noise_t])\n",
    "\n",
    "    metrics['epoch_wise_loss'].append(total_loss/len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {metrics['epoch_wise_loss'][-1]:.4f}\")\n",
    "\n",
    "metrics['epoch_wise_loss'] = [metrics['step_wise_loss'][0]] + metrics['epoch_wise_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757caf80-b064-4bc8-92af-55196eb37bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loss curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(metrics['step_wise_loss'], label=\"Per Step Loss\", color='blue')\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Per Step Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(metrics['epoch_wise_loss'], label=\"Per Epoch Loss\", color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Per Epoch Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b28f3-ac66-41f1-a6d4-46a285ba096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the model weights and the example\n",
    "# proteins saved during training\n",
    "# to avoid having to re-run the training\n",
    "# process in case the runtime crashes\n",
    "# during investigation of the results\n",
    "f = open(\"example_proteins.pkl\",\"wb\")\n",
    "pickle.dump(example_proteins,f)\n",
    "f.close()\n",
    "\n",
    "dict_to_save = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}\n",
    "torch.save(dict_to_save, 'model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b1afe-a4d8-4045-813f-0306b8f271a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the predicted noise from a noisy structure\n",
    "# based on time step of a chosen index,\n",
    "# to retrun the generated backbone\n",
    "idx = -7\n",
    "denoised = model.denoise_at_t(\n",
    "    example_proteins['noisy'][idx].detach().cpu(),\n",
    "    example_proteins['predicted_noise'][idx].detach().cpu(),\n",
    "    example_proteins['timestep'][idx].detach().cpu()\n",
    ")\n",
    "sample = denoised.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260ecaf-d491-4a21-b65f-daa37e4079c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a protein instance from the given input then render it\n",
    "\n",
    "## -> uncomment to plot the original backbone\n",
    "# sample = example_proteins['original'][idx].detach().cpu().numpy()\n",
    "\n",
    "# -> uncomment to plot the noisy backbone\n",
    "# sample = example_proteins['noisy'][idx].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "prot = model.get_protein(sample)\n",
    "\n",
    "pdb_str = to_pdb(prot)\n",
    "\n",
    "# Render.\n",
    "view = py3Dmol.view(\n",
    "    width=600, height=600, linked=True , viewergrid=(1, 1))\n",
    "view.setViewStyle({'style': 'outline', 'color': 'black', 'width': 0.1})\n",
    "style = {\"cartoon\": {'color': 'spectrum'}}\n",
    "\n",
    "view.addModelsAsFrames(pdb_str, viewer=(0, 0))\n",
    "view.setStyle({'model': -1}, style, viewer=(0, 0))\n",
    "view.zoomTo(viewer=(0, 0))\n",
    "\n",
    "view.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1f31e-d7ba-4cb9-b962-82bcf252b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfom sampling (needs a fix) and renders it\n",
    "model.eval()\n",
    "sample, samples_over_T, noise_over_T = model.sample((1, 256, 37, 3), device)\n",
    "sample = sample[0].detach().cpu().numpy()\n",
    "\n",
    "prot = model.get_protein(sample)\n",
    "\n",
    "pdb_str = to_pdb(prot)\n",
    "\n",
    "# Render.\n",
    "view = py3Dmol.view(\n",
    "    width=600, height=600, linked=True , viewergrid=(1, 1))\n",
    "view.setViewStyle({'style': 'outline', 'color': 'black', 'width': 0.1})\n",
    "style = {\"cartoon\": {'color': 'spectrum'}}\n",
    "\n",
    "view.addModelsAsFrames(pdb_str, viewer=(0, 0))\n",
    "view.setStyle({'model': -1}, style, viewer=(0, 0))\n",
    "view.zoomTo(viewer=(0, 0))\n",
    "\n",
    "view.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein-diffusion",
   "language": "python",
   "name": "protein-diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
